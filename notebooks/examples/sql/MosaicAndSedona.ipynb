{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf98136c-9276-4388-8eef-b567621fe1a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Mosaic & Sedona\n",
    "\n",
    "> You can combine the usage of [Mosaic](https://databrickslabs.github.io/mosaic/index.html) with other geospatial libraries. In this example we combine it with [Sedona](https://sedona.apache.org).\n",
    "\n",
    "## Setup\n",
    "\n",
    "This notebook will run if you have both Mosaic and Sedona installed on your cluster as described below.\n",
    "\n",
    "### Install Sedona\n",
    "\n",
    "To install Sedona, follow the [official Sedona instructions](https://sedona.apache.org/1.5.0/setup/databricks/).\n",
    "\n",
    "E.g. Add the following maven coordinates to a non-photon cluster [[1](https://docs.databricks.com/en/libraries/package-repositories.html)]. This is showing DBR 12.2 LTS.  \n",
    "\n",
    "```\n",
    "org.apache.sedona:sedona-spark-shaded-3.0_2.12:1.5.0\n",
    "org.datasyslab:geotools-wrapper:1.5.0-28.2\n",
    "```\n",
    "\n",
    "### Install Mosaic\n",
    "\n",
    "Download Mosaic JAR to your local machine (e.g. from [here](https://github.com/databrickslabs/mosaic/releases/download/v_0.3.12/mosaic-0.3.12-jar-with-dependencies.jar) for 0.3.12) and then UPLOAD to your cluster [[1](https://docs.databricks.com/en/libraries/cluster-libraries.html#install-a-library-on-a-cluster)]. \n",
    "\n",
    "### Notes\n",
    "\n",
    "* This is for [SPARK SQL](https://www.databricks.com/glossary/what-is-spark-sql#:~:text=Spark%20SQL%20is%20a%20Spark,on%20existing%20deployments%20and%20data.) which is different from [DBSQL](https://www.databricks.com/product/databricks-sql); __The best way to combine is to not register mosaic SQL functions since Sedona is primarily SQL.__\n",
    "* See instructions for `SedonaContext.create(spark)` [[1](https://sedona.apache.org/1.5.0/tutorial/sql/?h=sedonacontext#initiate-sedonacontext)]. \n",
    "* And, Sedona identifies that it might have issues if executed on a [Photon](https://www.databricks.com/product/photon) cluster; again this example is showing DBR 12.2 LTS on the Mosaic 0.3 series.\n",
    "\n",
    "--- \n",
    " __Last Update__ 01 DEC 2023 [Mosaic 0.3.12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27dd2429-1135-457b-912f-931e7aaa447e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Prior to Setup\n",
    "\n",
    "> Notice that even in DBR 12.2 LTS, Databricks initially has gated functions, meaning they will not execute on the runtime but are there. However, we will see that after registering functions, e.g. from Sedona, those then become available (in DBR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80dcd1b7-5f05-47a9-a5e5-f8361811cec4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "-- before we do anything\n",
    "-- have gated product functions\n",
    "show system functions like 'st_*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7cac536-773b-47a4-90ce-5a2c77bdca8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_The following exception will be thrown if you attempt to execute the gated functions:_\n",
    "\n",
    "```\n",
    "AnalysisException: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"st_area(POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10)))\" due to data type mismatch: parameter 1 requires (\"GEOMETRY\" or \"GEOGRAPHY\") type, however, \"POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))\" is of \"STRING\" type.; line 1 pos 7;\n",
    "'Project [unresolvedalias(st_area(POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))), None)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85cd6a7a-dd6d-4cf6-8f65-0ebf640c2ab2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "-- assumes you are in DBR 12.2 LTS\n",
    "-- so this will not execute\n",
    "-- uncomment to verify\n",
    "-- select st_area('POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4a24590-8542-4a71-a1c9-03690da5316e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "-- notice, e.g. these are initially gated product functions\n",
    "describe function extended st_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46dcda8a-cd24-4016-acf9-6ede54978d2f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "> We are installing Mosaic without SQL functions registered (via Scala) and are installing Sedona SQL as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c91dd7bf-319c-489c-9715-6c512f027d64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "\n",
    "// -- spark functions\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// -- mosaic functions\n",
    "import com.databricks.labs.mosaic.functions.MosaicContext\n",
    "import com.databricks.labs.mosaic.H3\n",
    "import com.databricks.labs.mosaic.JTS\n",
    "\n",
    "val mosaicContext = MosaicContext.build(H3, JTS)\n",
    "import mosaicContext.functions._\n",
    "\n",
    "// ! don't register SQL functions !\n",
    "// - this allows sedona to be the main spatial SQL provider\n",
    "//mosaicContext.register()\n",
    "\n",
    "// -- sedona functions\n",
    "import org.apache.sedona.spark.SedonaContext\n",
    "val sedona = SedonaContext.create(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a446841d-9ce1-4b0c-97e8-b705ab06caee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Now when we list user functions, we see all the Sedona provided ones._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0394a8a2-dcfd-49c0-a2df-85ecd0272029",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "show user functions like 'st_*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87fd220-d78e-402a-9452-e15191128a1b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Notice that the prior system registered functions have been replaced, e.g. `ST_Area`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d5f73c2-d7c1-4e61-bf15-41d51a1d3829",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "-- notice, e.g. the provided function now are available\n",
    "describe function extended st_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1805f461-ecab-4a03-980d-fb403a3a028e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Queries\n",
    "\n",
    "> Showing how Sedona (registered Spark SQL) and Mosaic (Scala) can co-exist on the same cluster. Not shown here, but the could also be Mosaic Python bindings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1e4ac30-daf0-423c-8117-b7c3c4c06e52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW sample AS (\n",
    "  SELECT 'POLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))' AS wkt\n",
    ");\n",
    "\n",
    "SELECT * FROM sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbb24b11-f88d-46fb-a365-773d35923704",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Here is a Spark SQL call to use the Sedona functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f44c258-6919-43bc-9b52-a9167ce48078",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT ST_Area(ST_GeomFromText(wkt)) AS sedona_area FROM sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a484604-c4bc-4234-acf0-32994de54554",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Here is Scala call to the same Mosaic-provided `ST_Area` function._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccf12e8d-82ff-47d9-ab5e-f64b2c487223",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "// verify scala functions registered\n",
    "display(\n",
    "  spark\n",
    "  .table(\"sample\")\n",
    "    .select(st_area($\"wkt\").as(\"mosaic_area\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dd1e21d-7a84-4c5e-b5f6-b02831d846b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Mosaic + Sedona_\n",
    "\n",
    "> Showing blending Mosaic calls (in Scala) with Sedona (Spark SQL) calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0602e02-01ec-45cd-8c17-aa30e0d0d969",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "display(\n",
    "  spark.table(\"sample\")\n",
    "    .select(\n",
    "      st_area($\"wkt\").as(\"mosaic_area\"),                    // <- mosaic (scala)\n",
    "      expr(\"ST_Area(ST_GeomFromText(wkt)) AS sedona_area\"), // <- sedona (spark sql)\n",
    "      $\"wkt\"\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2308237406562953,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "MosaicAndSedona",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
