{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89a84928-6a2b-4aaa-b7b1-c2e011199bfb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Shapely Validate Example \n",
    "\n",
    "> Parallel handling of of a mixture of valid and invalid geometries using [regular](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udf.html?highlight=udf#pyspark.sql.functions.udf) and [vectorized pandas](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pandas_udf.html?highlight=pandas%20udf#pyspark.sql.functions.pandas_udf) UDFs.\n",
    "\n",
    "__Libraries__\n",
    "\n",
    "<p/>\n",
    "\n",
    "* 'databricks-mosaic' (installs geopandas and dependencies as well as keplergl)\n",
    "\n",
    "--- \n",
    " __Last Update__ 22 NOV 2023 [Mosaic 0.3.12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9812f64-8eff-4888-8d15-85d60aa3464f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cc73475-225a-4f32-8ddc-93c564095776",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97b74931-0c94-41e6-afa3-b7a3236ecce2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install \"databricks-mosaic<0.4,>=0.3\" --quiet # <- Mosaic 0.3 series\n",
    "# %pip install \"databricks-mosaic<0.5,>=0.4\" --quiet # <- Mosaic 0.4 series (as available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d01ad97d-188a-4ce0-ab7c-28029e77d30b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -- configure AQE for more compute heavy operations\n",
    "#  - choose option-1 or option-2 below, essential for REPARTITION!\n",
    "# spark.conf.set(\"spark.databricks.optimizer.adaptive.enabled\", False) # <- option-1: turn off completely for full control\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False) # <- option-2: just tweak partition management\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 10_000)                 # <-- default is 200\n",
    "\n",
    "# -- import databricks + spark functions\n",
    "from pyspark.databricks.sql import functions as dbf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# -- setup mosaic\n",
    "import mosaic as mos\n",
    "\n",
    "mos.enable_mosaic(spark, dbutils)\n",
    "# mos.enable_gdal(spark) # <- not needed for this example\n",
    "\n",
    "# --other imports\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9620eaf-3776-4ea4-b5b9-f7da9f164a8f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data\n",
    "\n",
    "> Generating a dataset with some bad data, adapted from [here](https://github.com/kleunen/boost_geometry_correct).\n",
    "\n",
    "These are the types of issues that can come up with geometries [[1](https://stackoverflow.com/questions/49902090/dataset-of-invalid-geometries-in-boostgeometry)]...\n",
    "\n",
    "```\n",
    "//Hole Outside Shell\n",
    "check(\"POLYGON((0 0, 10 0, 10 10, 0 10, 0 0), (15 15, 15 20, 20 20, 20 15, 15 15))\");\n",
    "//Nested Holes\n",
    "check(\"POLYGON((0 0, 10 0, 10 10, 0 10, 0 0), (2 2, 2 8, 8 8, 8 2, 2 2), (3 3, 3 7, 7 7, 7 3, 3 3))\");\n",
    "//Disconnected Interior\n",
    "check(\"POLYGON((0 0, 10 0, 10 10, 0 10, 0 0), (5 0, 10 5, 5 10, 0 5, 5 0))\");\n",
    "//Self Intersection\n",
    "check(\"POLYGON((0 0, 10 10, 0 10, 10 0, 0 0))\");\n",
    "//Ring Self Intersection\n",
    "check(\"POLYGON((5 0, 10 0, 10 10, 0 10, 0 0, 5 0, 3 3, 5 6, 7 3, 5 0))\");\n",
    "//Nested Shells\n",
    "check<multi>(\"MULTIPOLYGON(((0 0, 10 0, 10 10, 0 10, 0 0)),(( 2 2, 8 2, 8 8, 2 8, 2 2)))\");\n",
    "//Duplicated Rings\n",
    "check<multi>(\"MULTIPOLYGON(((0 0, 10 0, 10 10, 0 10, 0 0)),((0 0, 10 0, 10 10, 0 10, 0 0)))\");\n",
    "//Too Few Points\n",
    "check(\"POLYGON((2 2, 8 2))\");\n",
    "//Invalid Coordinate\n",
    "check(\"POLYGON((NaN 3, 3 4, 4 4, 4 3, 3 3))\");\n",
    "//Ring Not Closed\n",
    "check(\"POLYGON((0 0, 0 10, 10 10, 10 0))\");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f9928a2-3172-4240-a4b2-e08a5b15467c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_wkts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "253969cc-ecd7-4e59-b5c5-3ab52d52240a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__[1a] Polygon self-intersection__\n",
    "\n",
    "> Exterior xy plot with shapely (to see the lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d25d6b19-d6da-49bc-a1cc-b5bb43306984",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_wkts.append((1, \"\"\"POLYGON ((5 0, 2.5 9, 9.5 3.5, 0.5 3.5, 7.5 9, 5 0))\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4416db98-d3e2-4548-a761-40745f49c98b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(*shapely.wkt.loads(test_wkts[0][1]).exterior.xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ff48a09-e1e8-4a2a-b125-9e88b9aaabb0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__[1b] Polygon with hole inside__\n",
    "\n",
    "> Exterior xy plot with shapely (to see the lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ba0913-ea2f-48e0-b381-35f6fbe453fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_wkts.append((2, \"\"\"POLYGON ((55 10, 141 237, 249 23, 21 171, 252 169, 24 89, 266 73, 55 10))\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a0264fa-c032-4740-a00f-82592de824bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(*shapely.wkt.loads(test_wkts[1][1]).exterior.xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79eecc6e-ddc8-4223-97d6-5474b5e34d37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__[1c] Polygon with multiple intersections at same point__\n",
    "\n",
    "> Exterior xy plot with shapely (to see the lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08a50a1d-f9c1-420c-b79b-7983d01bf5c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_wkts.append((3, \"\"\"POLYGON ((0 0, 10 0, 0 10, 10 10, 0 0, 5 0, 5 10, 0 10, 0 5, 10 5, 10 0, 0 0))\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eeb16d7-5f2b-44d1-b6b5-36e45d65e9e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(*shapely.wkt.loads(test_wkts[2][1]).exterior.xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca173a4d-639d-4659-937e-aa3bdb5a8c55",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__[1d] Valid Polygon__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc2f019a-d4c1-4a68-94e7-be14e9288ac2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_wkts.append((4, \"\"\"POLYGON (( -84.3641541604937 33.71316821215546, -84.36414611386687 33.71303657522174, -84.36409515189553 33.71303657522174, -84.36410319852232 33.71317267442025, -84.3641541604937 33.71316821215546 ))\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a7735bb-ff89-4357-8b89-f991776e045a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(*shapely.wkt.loads(test_wkts[3][1]).exterior.xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c67147a4-505d-4be1-a36d-68d27643e925",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__[2] Make Spark DataFrame from `test_wkts`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e65a616e-9abe-4c52-b8f2-06b789188bc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "  spark\n",
    "    .createDataFrame(test_wkts, schema=['row_id', 'geom_wkt'])\n",
    ")\n",
    "print(f\"count? {df.count():,}\")\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea4d2ea0-1224-41f6-ae5b-72f2c34b9a5b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Regular UDF: Test + Fix Validity\n",
    "\n",
    "> Will use Mosaic to initially test; then only apply UDF to invalids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfdaa108-3c66-404e-ac2a-a6de18cbd5d4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f99ec990-0629-446c-90ff-447d6496f260",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def explain_wkt_validity(geom_wkt:str) -> str:\n",
    "    \"\"\"\n",
    "    Add explanation of validity or invalidity\n",
    "    \"\"\"\n",
    "    from shapely import wkt\n",
    "    from shapely.validation import explain_validity\n",
    "\n",
    "    _geom = wkt.loads(geom_wkt)\n",
    "    return explain_validity(_geom)\n",
    "\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def make_wkt_valid(geom_wkt:str) -> str:\n",
    "    \"\"\"\n",
    "    - test for wkt being valid\n",
    "    - attempts to make valid\n",
    "    - may have to change type, e.g. POLYGON to MULTIPOLYGON\n",
    "     returns valid wkt\n",
    "    \"\"\"\n",
    "    from shapely import wkt \n",
    "    from shapely.validation import make_valid\n",
    "\n",
    "    _geom = wkt.loads(geom_wkt)\n",
    "    if _geom.is_valid:\n",
    "        return geom_wkt\n",
    "    _geom_fix = make_valid(_geom)\n",
    "    return _geom_fix.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aad1c6ee-183f-4e74-92bf-07e94ff2c81e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Test Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f38c18f1-3248-4c48-ae3f-6872618d168b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test_valid = (\n",
    "  df\n",
    "    .withColumn(\"is_valid\", mos.st_isvalid(\"geom_wkt\"))\n",
    ")\n",
    "\n",
    "df_test_valid.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a87a8fd9-1fd1-44be-9704-7995bf7f2bea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Let's get an explanation for our 3 invalids__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f783941-c167-4135-a1a2-8ebe969c66f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Recommend `explain_wkt_valid` only to help you understand, not as part of production pipeline, so doing separately._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47ed3341-8321-47e1-a9ec-ef67ff4fd007",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "  df_test_valid\n",
    "  .select(\n",
    "    \"*\",\n",
    "    F\n",
    "      .when(col(\"is_valid\") == False, explain_wkt_validity(\"geom_wkt\"))\n",
    "      .otherwise(F.lit(None))\n",
    "      .alias(\"invalid_explain\")\n",
    "  )\n",
    "  .filter(\"is_valid = false\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7b716ae-f63c-47f2-91c7-7ae9f08d8114",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Fix Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e25db3fb-e1ea-48d8-ba36-65082da5e933",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_valid = (\n",
    "  df\n",
    "    .withColumnRenamed(\"geom_wkt\", \"orig_geom_wkt\")\n",
    "    .withColumn(\"is_orig_valid\", mos.st_isvalid(\"orig_geom_wkt\"))\n",
    "  .select(\n",
    "    \"*\",\n",
    "    F\n",
    "      .when(col(\"is_orig_valid\") == False, make_wkt_valid(\"orig_geom_wkt\"))\n",
    "      .otherwise(col(\"orig_geom_wkt\"))\n",
    "      .alias(\"geom_wkt\")\n",
    "  )\n",
    "  .withColumn(\"is_valid\", mos.st_isvalid(\"geom_wkt\"))\n",
    "  .drop(\"orig_geom_wkt\")\n",
    ")\n",
    "\n",
    "print(f\"\"\"count? {df_valid.count():,}\"\"\")\n",
    "print(f\"\"\"num orig invalid? {df_valid.filter(col(\"is_orig_valid\") == False).count():,}\"\"\")\n",
    "print(f\"\"\"num final invalid? {df_valid.filter(col(\"is_valid\") == False).count():,}\"\"\")\n",
    "display(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "705f56e7-ef65-4b66-8eca-46e6cc4e754c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fix_wkts = df_valid.orderBy('row_id').toJSON().collect()\n",
    "fix_wkts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8bada46-bbc5-4ffe-b4ef-a876ac3022df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Row 1: Fixed [Self-Intersection]__ \n",
    "\n",
    "> Using GeoPandas to plot area for fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac875ef1-124b-43e7-82a6-82a46dd5263e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpd.GeoSeries(shapely.wkt.loads(json.loads(fix_wkts[0])['geom_wkt'])).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76452d6e-53ad-4075-8552-c66b877c8801",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Row 2: Fixed [Self-Intersection]__\n",
    "\n",
    "> Using GeoPandas to plot area for fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd70ddc-cef4-405f-8b85-b732691e53ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpd.GeoSeries(shapely.wkt.loads(json.loads(fix_wkts[1])['geom_wkt'])).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fadc613-c5b2-464e-a718-c1e76ec1a208",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Row 3: Fixed [Ring Self-Intersection]__\n",
    "\n",
    "> Using GeoPandas to plot area for fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9e3d0eb-718a-41cc-bae2-fccf1e0d6cd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpd.GeoSeries(shapely.wkt.loads(json.loads(fix_wkts[2])['geom_wkt'])).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "230bf52a-3b2e-4c65-8cf7-5098af27c943",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Option: Vectorized Pandas UDF\n",
    "\n",
    "> If you want to go further with performance, you can use a vectorized pandas UDF\n",
    "\n",
    "__Note: We are using the Pandas Series [Vectorized UDF](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pandas_udf.html) variant.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77c2b320-f5b1-4a27-90de-820e6e0886a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "import pandas as pd\n",
    "\n",
    "@pandas_udf(StringType())\n",
    "def vectorized_make_wkt_valid(s:pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    - test for wkt being valid\n",
    "    - attempts to make valid\n",
    "    - may have to change type, e.g. POLYGON to MULTIPOLYGON\n",
    "     returns valid wkt\n",
    "    \"\"\"\n",
    "    from shapely import wkt \n",
    "    from shapely.validation import make_valid\n",
    "\n",
    "    def to_valid(w:str) -> str:\n",
    "      _geom = wkt.loads(w)\n",
    "      if _geom.is_valid:\n",
    "        return w\n",
    "      _geom_fix = make_valid(_geom)\n",
    "      return _geom_fix.wkt\n",
    "\n",
    "    return s.apply(to_valid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c63edd3-f87e-4ede-bf74-c1d49c7177e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_This variation doesn't show all the interim testing, just the fixing._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b871326-d013-49c0-863f-51e5c16ddd60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_valid1 = (\n",
    "  df                                                                                   # <- initial dataframe\n",
    "    .withColumnRenamed(\"geom_wkt\", \"orig_geom_wkt\")\n",
    "    .withColumn(\"is_orig_valid\", mos.st_isvalid(\"orig_geom_wkt\"))\n",
    "    .repartition(sc.defaultParallelism * 8, \"orig_geom_wkt\")                           # <- useful at scale\n",
    "  .select(\n",
    "    \"*\",\n",
    "    F\n",
    "      .when(col(\"is_orig_valid\") == False, vectorized_make_wkt_valid(\"orig_geom_wkt\")) # <- Pandas UDF\n",
    "      .otherwise(col(\"orig_geom_wkt\"))\n",
    "      .alias(\"geom_wkt\")\n",
    "  )\n",
    "  .withColumn(\"is_valid\", mos.st_isvalid(\"geom_wkt\"))\n",
    "  .drop(\"orig_geom_wkt\")\n",
    ")\n",
    "\n",
    "print(f\"\"\"count? {df_valid1.count():,}\"\"\")\n",
    "print(f\"\"\"num orig invalid? {df_valid1.filter(col(\"is_orig_valid\") == False).count():,}\"\"\")\n",
    "print(f\"\"\"num final invalid? {df_valid1.filter(col(\"is_valid\") == False).count():,}\"\"\")\n",
    "display(df_valid1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebff4ab-4d1e-4339-9182-e52d427e4071",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> _To further optimize as an automated workflow, you would writing to Delta Tables and avoiding unnecessary calls to `count` / `display`._\n",
    "\n",
    "__Notes:__\n",
    "\n",
    "* At-scale, there are benefits to adding call like `.repartition(sc.defaultParallelism * 8, \"orig_geom_wkt\")` when coupled with spark confs to adjust AQE (see top of notebook) as this give you more control of partitioning since there is compute-heavy (aka UDF) tasks that Spark cannot plan for as well as a \"pure\" data-heavy operation.\n",
    "* The focus of this notebook was not on rendering on a map, so we just used matplot lib with both Shapely (for pre-fixed geoms) and GeoPandas (for fixed geoms)\n",
    "* The use of `.when()` conditional allows us to avoid UDF calls except where `is_valid=False` which saves on unnecessary compute time\n",
    "* We avoided shapely `explain_validity` call except to initially understand as that call can be computationally expensive (and is only informational)\n",
    "* This is just a subset of validation, but hopefully offers enough breadcrumbs for common issues you may face when processing invalid geometries"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 85549841996182,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "shapely_validate_udfs",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
